# -*- coding: utf-8 -*-
"""import data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-d7Clz4nD6eV7z34dUhLq8ijbPzCZAOX
"""

data_dir = "/content/sample_data/"
    datsize_file = data_dir + "Foursquare_data_size.txt"
    check_in_file = data_dir + "Foursquare_checkins.txt"
    train_file = data_dir + "Foursquare_train.txt"
    tune_file = data_dir + "Foursquare_tune.txt"
    test_file = data_dir + "Foursquare_test.txt"
    poi_file = data_dir + "Foursquare_poi_coos.txt"

    num_users, num_poiss = open(datsize_file, 'r').readlines()[0].strip('\n').split()
    num_users, num_poiss = int(num_users), int(num_pois)
    top_n = 50
    gamma = 50.0
    GMM = GeographyMultiCenterModel()
    GM = GeographicalModule(alpha=0.9)
    import scipy.sparse as sparse
import numpy as np
import time
from collections import defaultdict



def read_training_data():
    train_data = open(train_file, 'r').readlines()
    sparse_training_matrix = sparse.dok_matrix((num_users, num_pois))
    user_poi_matrix = np.zeros((num_users, num_pois))
    user_poi_weighted_matrix = np.zeros((num_users, num_pois))
    training_tuples = set()
    coo_rows = []
    coo_cols = []
    coo_data = []
    for eachline in train_data:
        uid, pid, freq = eachline.strip().split()
        uids, pids, freqs = int(uid), int(pid), int(freq)
          coo_rows.append(uids)
          coo_cols.append(pids)
          coo_data.append(freqs)
          sparse_training_matrix[uids, pids] = freqs
          user_poi_matrix[uids, pids] = freqs
          user_poi_weighted_matrix[uids, pids] = 1 + gamma * np.log(1 + freqs)
          training_tuples.add((uids, pids))
    coo_rows = np.array(coo_rows)
    coo_cols = np.array(coo_cols)
    coo_data = np.array(coo_data)
    print(coo_rows.shape)
    print(coo_cols.shape)
    print(coo_data.shape)
    shape = sparse_training_matrix.shape
    coo_matrix_training = sparse.coo_matrix((coo_data, (coo_rows, coo_cols)), shape=shape)
    return sparse_training_matrix, training_tuples, user_poi_matrix, user_poi_weighted_matrix,coo_matrix_training


def read_ground_truth():
    ground_truth = defaultdict(set)
    truth_data = open(test_file, 'r').readlines()
    for eachline in truth_data:
        uid, pid, _ = eachline.strip().split()
        uid, pid = int(uid), int(pid)
        ground_truth[uid].add(pid)
    return ground_truth


def read_poi_coos():
    poi_coos = {}
    poi_data = open(poi_file, 'r').readlines()
    for eachline in poi_data:
        pid, lat, lng = eachline.strip().split()
        pid, lat, lng = int(pid), float(lat), float(lng)
        poi_coos[pid] = (lat, lng)
    return poi_coos



sparse_training_matrixD, training_tuples, user_poi_matrix, user_poi_weighted_matrix ,coo_matrix_training = read_training_data()
ground_truth = read_ground_truth()
poi_coos = read_poi_coos()