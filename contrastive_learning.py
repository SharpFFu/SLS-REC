# -*- coding: utf-8 -*-
"""contrastive learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14hwI9wEAcVWD2IlNQELYjDUQwr1UrEph
"""

import torch
import tensorflow as tf
from scipy.sparse import coo_matrix
import numpy as np
import os

from math import sqrt
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

import datetime
import math
import numpy as np

from torch import nn, backends
from torch.nn import Module, Parameter
import torch.nn.functional as F
import torch.sparse
from scipy.sparse import coo
import time

!pip install --upgrade torch-scatter
!pip install --upgrade torch-sparse
!pip install --upgrade torch-cluster
!pip install --upgrade torch-spline-conv
!pip install torch-geometric

result_10 = open('/content/sample_data/' + str(10) + '.txt', 'w')
result_20 = open('/content/sample_data/' + str(20) + '.txt', 'w')
loss_fn = torch.nn.BCEWithLogitsLoss(reduce=True, size_average=True)

result_10 = open('/content/sample_data/' + str(10) + '.txt', 'w')
result_20 = open('/content/sample_data/' + str(20) + '.txt', 'w')
all_uids = list(range(num_users))
all_pids = list(range(num_pois))
np.random.shuffle(all_uids)
precision_10, recall_10, nDCG_10, MAP_10, precision_10h, recall_10h = [], [], [], [], [], []
precision_20, recall_20, nDCG_20, MAP_20, precision_20h, recall_20h = [], [], [], [], [], []
print("Start Predicting...")
for cnt, uid in enumerate(all_uids):
    print(cnt)
    if uid in ground_truth:
        GM_scores = [GM.predict(uid, pid, user_poi_matrix, poi_coos, user_centers) if (uid, pid) not in training_tuples else -1 for pid in all_pids]
        GMM_scores = [GMM_h.predict(uid, pid, user_poi_matrix, poi_coos, user_centers_h) if (uid, pid) not in training_tuples else -1 for pid in all_pids]
        GM_tensor =torch.Tensor(GM_scores)

        GMM_tensor =torch.Tensor(GMM_scores)

        loss = loss_fn (GM_tensor.float(),GMM_tensor.float())
        overall_scores_N = np.array(GM_scores)
        overall_scores_H = np.array(GMM_scores)
        predicted_n = list(reversed(overall_scores_N.argsort()))[:top_n]
        predicted_h = list(reversed(overall_scores_H.argsort()))[:top_n]
        actual = ground_truth[uid]
        if type(predicted[1]).__name__ == 'ndarray':
          pass

        else:
          loss = loss.item()
          if pd.isnull(loss):
             loss = 0.5
          precision_10.append(precisionk(actual, predicted_n[:10]))
          recall_10.append(recallk(actual, predicted_n[:10]))
          precision_20.append(precisionk(actual, predicted_n[:20]))
          recall_20.append(recallk(actual, predicted_n[:20]))

          precision_10h.append(precisionk(actual, predicted_h[:10]))
          recall_10h.append(recallk(actual, predicted_h[:10]))
          precision_20h.append(precisionk(actual, predicted_h[:20]))
          recall_20h.append(recallk(actual, predicted_h[:20]))

          result_10.write('\t'.join([str(cnt), str(uid), str(np.mean(precision_10)*loss+np.mean(precision_10h)*(1-loss)), str(np.mean(recall_10)*loss+np.mean(recall_10h)*(1-loss))]) + '\n')
          p10=p10 + (np.mean(precision_10)*loss+(np.mean(precision_10h)*(1-loss)))
          r10=r10 + (np.mean(recall_10)*loss+np.mean(recall_10h)*(1-loss))
          result_20.write('\t'.join([str(cnt), str(uid), str(np.mean(precision_20)*loss+np.mean(precision_20h)*(1-loss)), str(np.mean(recall_20)*loss+np.mean(recall_20h)*(1-loss))]) + '\n')
          p20=p20 + (np.mean(precision_20)*loss+np.mean(precision_20h)*(1-loss))
          r20=r10 + (np.mean(recall_20)*loss+np.mean(recall_20h)*(1-loss))

print("Task Finished!")